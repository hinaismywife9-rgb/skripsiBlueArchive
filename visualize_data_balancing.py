import matplotlib.pyplot as plt
import numpy as np

# Data balancing information
methods = ['Original\n(Imbalanced)', 'Oversampling', 'Undersampling', 'Hybrid\n(Selected)']
negative = [805, 805, 395, 600]
positive = [395, 805, 395, 600]
total = [1200, 1610, 790, 1200]

colors_neg = ['#d62728', '#d62728', '#d62728', '#d62728']
colors_pos = ['#1f77b4', '#1f77b4', '#1f77b4', '#1f77b4']

# ============================================================
# FIGURE 1: STACKED BAR CHART
# ============================================================
fig, ax = plt.subplots(figsize=(12, 7))

x = np.arange(len(methods))
width = 0.6

bars1 = ax.bar(x, negative, width, label='Negative', color=colors_neg, alpha=0.85)
bars2 = ax.bar(x, positive, width, bottom=negative, label='Positive', color=colors_pos, alpha=0.85)

ax.set_ylabel('Number of Samples', fontweight='bold', fontsize=12)
ax.set_title('Data Balancing Techniques Comparison - Class Distribution', 
             fontweight='bold', fontsize=13, pad=15)
ax.set_xticks(x)
ax.set_xticklabels(methods, fontweight='bold', fontsize=11)
ax.legend(loc='upper right', fontsize=11, framealpha=0.95)
ax.grid(axis='y', alpha=0.3, linestyle='--')

# Add value labels on bars
for i, method in enumerate(methods):
    ax.text(i, negative[i]/2, f'{negative[i]}', ha='center', va='center', 
            fontweight='bold', fontsize=10, color='white')
    ax.text(i, negative[i] + positive[i]/2, f'{positive[i]}', ha='center', va='center', 
            fontweight='bold', fontsize=10, color='white')
    ax.text(i, negative[i] + positive[i] + 30, f'Total: {total[i]}', 
            ha='center', va='bottom', fontweight='bold', fontsize=10)

# Add imbalance ratio
ratios = ['2.04:1', '1:1', '1:1', '1:1']
for i, ratio in enumerate(ratios):
    ax.text(i, -150, f'Ratio: {ratio}', ha='center', va='top', fontsize=9, 
            style='italic', color='gray')

ax.set_ylim(0, max(total) + 300)
plt.tight_layout()
plt.savefig('data_balancing_comparison.png', dpi=300, bbox_inches='tight')
print('‚úì Saved: data_balancing_comparison.png')
plt.close()

# ============================================================
# FIGURE 2: CLASS PERCENTAGE PIE CHARTS
# ============================================================
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
fig.suptitle('Class Distribution Before and After Balancing', 
             fontweight='bold', fontsize=14, y=0.995)

# Original
ax = axes[0, 0]
sizes = [805, 395]
labels = ['Negative\n(67.1%)', 'Positive\n(32.9%)']
colors = ['#d62728', '#1f77b4']
explode = (0.05, 0.05)
ax.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',
       shadow=True, startangle=90, textprops={'fontsize': 11, 'weight': 'bold'})
ax.set_title('Original (Imbalanced)\nTotal: 1,200', fontweight='bold', fontsize=11)

# Oversampling
ax = axes[0, 1]
sizes = [805, 805]
labels = ['Negative\n(50.0%)', 'Positive\n(50.0%)']
colors = ['#d62728', '#1f77b4']
explode = (0, 0)
ax.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',
       shadow=True, startangle=90, textprops={'fontsize': 11, 'weight': 'bold'})
ax.set_title('Oversampling\nTotal: 1,610', fontweight='bold', fontsize=11)

# Undersampling
ax = axes[1, 0]
sizes = [395, 395]
labels = ['Negative\n(50.0%)', 'Positive\n(50.0%)']
colors = ['#d62728', '#1f77b4']
explode = (0, 0)
ax.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',
       shadow=True, startangle=90, textprops={'fontsize': 11, 'weight': 'bold'})
ax.set_title('Undersampling\nTotal: 790', fontweight='bold', fontsize=11)

# Hybrid (Selected)
ax = axes[1, 1]
sizes = [600, 600]
labels = ['Negative\n(50.0%)', 'Positive\n(50.0%)']
colors = ['#d62728', '#1f77b4']
explode = (0, 0)
wedges, texts, autotexts = ax.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',
       shadow=True, startangle=90, textprops={'fontsize': 11, 'weight': 'bold'})
ax.set_title('Hybrid (Selected) ‚≠ê\nTotal: 1,200', fontweight='bold', fontsize=11, 
             bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))

plt.tight_layout()
plt.savefig('data_balancing_pie_charts.png', dpi=300, bbox_inches='tight')
print('‚úì Saved: data_balancing_pie_charts.png')
plt.close()

# ============================================================
# FIGURE 3: TRANSFORMATION FLOW
# ============================================================
fig, ax = plt.subplots(figsize=(14, 8))
ax.axis('off')

# Title
ax.text(0.5, 0.95, 'Data Balancing Transformation Flow', 
        ha='center', va='top', fontsize=16, fontweight='bold',
        transform=ax.transAxes)

# Original box
ax.add_patch(plt.Rectangle((0.05, 0.75), 0.9, 0.15, 
                          fill=True, facecolor='#ffcccc', edgecolor='#d62728', linewidth=2))
ax.text(0.5, 0.87, 'ORIGINAL DATA: 1,200 samples', ha='center', va='center', 
        fontsize=12, fontweight='bold', transform=ax.transAxes)
ax.text(0.5, 0.80, 'Negative: 805 (67.1%) | Positive: 395 (32.9%)', 
        ha='center', va='center', fontsize=11, transform=ax.transAxes, style='italic')

# Arrow 1
ax.annotate('', xy=(0.5, 0.73), xytext=(0.5, 0.76),
            arrowprops=dict(arrowstyle='->', lw=2.5, color='black'),
            xycoords='axes fraction')
ax.text(0.55, 0.745, 'Apply Hybrid Balancing', fontsize=10, 
        transform=ax.transAxes, style='italic', color='green', fontweight='bold')

# Processing description
ax.text(0.5, 0.68, 'Process:', ha='center', va='center', fontsize=11, 
        fontweight='bold', transform=ax.transAxes)
ax.text(0.5, 0.64, '1. Negative: 805 ‚Üí 600 (reduce by 25.5%, keep only diverse samples)', 
        ha='center', va='center', fontsize=9, transform=ax.transAxes)
ax.text(0.5, 0.60, '2. Positive: 395 ‚Üí 600 (increase by 51.9%, replicate underrepresented samples)', 
        ha='center', va='center', fontsize=9, transform=ax.transAxes)
ax.text(0.5, 0.56, '3. Result: Perfect 50-50 balance (600 vs 600)', 
        ha='center', va='center', fontsize=9, transform=ax.transAxes, 
        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))

# Arrow 2
ax.annotate('', xy=(0.5, 0.53), xytext=(0.5, 0.56),
            arrowprops=dict(arrowstyle='->', lw=2.5, color='black'),
            xycoords='axes fraction')

# Final box
ax.add_patch(plt.Rectangle((0.05, 0.33), 0.9, 0.15, 
                          fill=True, facecolor='#ccffcc', edgecolor='#2ca02c', linewidth=2))
ax.text(0.5, 0.45, '‚úÖ BALANCED DATA: 1,200 samples', ha='center', va='center', 
        fontsize=12, fontweight='bold', transform=ax.transAxes, color='green')
ax.text(0.5, 0.40, 'Negative: 600 (50.0%) | Positive: 600 (50.0%)', 
        ha='center', va='center', fontsize=11, transform=ax.transAxes, style='italic')
ax.text(0.5, 0.35, 'Perfect balance, ready for training!', 
        ha='center', va='center', fontsize=10, transform=ax.transAxes, 
        style='italic', color='green', fontweight='bold')

# Why section
ax.add_patch(plt.Rectangle((0.05, 0.05), 0.9, 0.22, 
                          fill=True, facecolor='#e6f2ff', edgecolor='#1f77b4', linewidth=1))
ax.text(0.5, 0.24, 'Why Hybrid Method?', ha='center', va='top', fontsize=11, 
        fontweight='bold', transform=ax.transAxes)
ax.text(0.5, 0.20, '‚úì Moderate dataset size (1,200 = balanced)', 
        ha='center', va='center', fontsize=9, transform=ax.transAxes)
ax.text(0.5, 0.16, '‚úì Reasonable training time (faster than oversampling only)', 
        ha='center', va='center', fontsize=9, transform=ax.transAxes)
ax.text(0.5, 0.12, '‚úì Minimal overfitting (fewer duplicates than pure oversampling)', 
        ha='center', va='center', fontsize=9, transform=ax.transAxes)
ax.text(0.5, 0.08, '‚úì Minimal data loss (less aggressive undersampling)', 
        ha='center', va='center', fontsize=9, transform=ax.transAxes)

plt.tight_layout()
plt.savefig('data_balancing_transformation_flow.png', dpi=300, bbox_inches='tight')
print('‚úì Saved: data_balancing_transformation_flow.png')
plt.close()

# ============================================================
# FIGURE 4: TECHNIQUE COMPARISON TABLE
# ============================================================
fig, ax = plt.subplots(figsize=(14, 8))
ax.axis('off')

# Title
ax.text(0.5, 0.98, 'Comparison of Data Balancing Techniques', 
        ha='center', va='top', fontsize=16, fontweight='bold',
        transform=ax.transAxes)

# Table data
table_data = [
    ['Aspect', 'Oversampling', 'Undersampling', 'Hybrid ‚≠ê'],
    ['Total Samples', '1,610', '790', '1,200'],
    ['Negative Samples', '805', '395', '600'],
    ['Positive Samples', '805', '395', '600'],
    ['Balance Ratio', '1:1', '1:1', '1:1'],
    ['Training Time', '‚ö†Ô∏è Slow', '‚úÖ Fast', '‚úÖ Medium'],
    ['Data Duplication', '‚ùå High', '‚úÖ None', '‚úÖ Low'],
    ['Data Loss', '‚úÖ None', '‚ùå High', '‚úÖ Low'],
    ['Overfitting Risk', '‚ö†Ô∏è High', '‚úÖ Low', '‚úÖ Low'],
    ['Underfitting Risk', '‚úÖ Low', '‚ùå High', '‚úÖ Low'],
    ['Overall Score', '‚≠ê‚≠ê‚≠ê', '‚≠ê‚≠ê‚≠ê', '‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê'],
]

table = ax.table(cellText=table_data, cellLoc='center', loc='center',
                colWidths=[0.25, 0.25, 0.25, 0.25])
table.auto_set_font_size(False)
table.set_fontsize(10)
table.scale(1, 2.5)

# Style header
for i in range(4):
    table[(0, i)].set_facecolor('#4472C4')
    table[(0, i)].set_text_props(weight='bold', color='white', size=11)

# Style rows
for i in range(1, len(table_data)):
    for j in range(4):
        if j == 3:  # Hybrid column
            table[(i, j)].set_facecolor('#ccffcc')
        elif i % 2 == 0:
            table[(i, j)].set_facecolor('#f0f0f0')
        else:
            table[(i, j)].set_facecolor('white')
        
        table[(i, j)].set_text_props(weight='bold' if j == 0 else 'normal')

# Add legend at bottom
legend_text = ('Best choice for our dataset:\n'
              'HYBRID (1,200 samples, 50-50 balance)\n'
              'Achieves: 99.15% F1-Score with DistilBERT')
ax.text(0.5, 0.02, legend_text, ha='center', va='bottom', fontsize=10,
        transform=ax.transAxes, style='italic',
        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))

plt.tight_layout()
plt.savefig('data_balancing_technique_comparison.png', dpi=300, bbox_inches='tight')
print('‚úì Saved: data_balancing_technique_comparison.png')
plt.close()

# ============================================================
# FIGURE 5: BEFORE AND AFTER COMPARISON
# ============================================================
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

# Before
categories = ['Negative', 'Positive']
before_values = [805, 395]
colors = ['#d62728', '#1f77b4']

bars1 = ax1.bar(categories, before_values, color=colors, alpha=0.85, width=0.6)
ax1.set_ylabel('Number of Samples', fontweight='bold', fontsize=12)
ax1.set_title('BEFORE Balancing\n(Imbalanced: 2.04:1 ratio)', 
              fontweight='bold', fontsize=12, color='red')
ax1.set_ylim(0, 1000)
ax1.grid(axis='y', alpha=0.3, linestyle='--')

# Add value labels
for i, (bar, val) in enumerate(zip(bars1, before_values)):
    percentage = (val / 1200) * 100
    ax1.text(bar.get_x() + bar.get_width()/2, val + 20, 
            f'{val}\n({percentage:.1f}%)', 
            ha='center', va='bottom', fontweight='bold', fontsize=11)

# Add problem annotation
ax1.text(0.5, 0.95, '‚ùå PROBLEM:\nModel learns to predict\nmajority class only!', 
         ha='center', va='top', fontsize=10, transform=ax1.transAxes,
         bbox=dict(boxstyle='round', facecolor='#ffcccc', alpha=0.8),
         fontweight='bold', color='red')

# After
after_values = [600, 600]

bars2 = ax2.bar(categories, after_values, color=colors, alpha=0.85, width=0.6)
ax2.set_ylabel('Number of Samples', fontweight='bold', fontsize=12)
ax2.set_title('AFTER Balancing (Hybrid)\n(Perfectly Balanced: 1:1 ratio)', 
              fontweight='bold', fontsize=12, color='green')
ax2.set_ylim(0, 1000)
ax2.grid(axis='y', alpha=0.3, linestyle='--')

# Add value labels
for i, (bar, val) in enumerate(zip(bars2, after_values)):
    percentage = (val / 1200) * 100
    ax2.text(bar.get_x() + bar.get_width()/2, val + 20, 
            f'{val}\n({percentage:.1f}%)', 
            ha='center', va='bottom', fontweight='bold', fontsize=11)

# Add solution annotation
ax2.text(0.5, 0.95, '‚úÖ SOLUTION:\nModel learns to distinguish\nboth classes equally!', 
         ha='center', va='top', fontsize=10, transform=ax2.transAxes,
         bbox=dict(boxstyle='round', facecolor='#ccffcc', alpha=0.8),
         fontweight='bold', color='green')

plt.tight_layout()
plt.savefig('data_balancing_before_after.png', dpi=300, bbox_inches='tight')
print('‚úì Saved: data_balancing_before_after.png')
plt.close()

print('\n' + '='*70)
print('‚úÖ ALL DATA BALANCING VISUALIZATIONS COMPLETE')
print('='*70)
print('\nüìä Generated Figures:')
print('  1. data_balancing_comparison.png')
print('  2. data_balancing_pie_charts.png')
print('  3. data_balancing_transformation_flow.png')
print('  4. data_balancing_technique_comparison.png')
print('  5. data_balancing_before_after.png')
print('\nüéØ Key Finding: HYBRID method achieves perfect balance')
print('   with reasonable dataset size and minimal overfitting')
print('='*70)
